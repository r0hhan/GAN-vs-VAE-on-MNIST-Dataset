# -*- coding: utf-8 -*-
"""mnist-vae.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LeUGbhXNY1IUnyGDWcqA7ns-JIFxd6Qm
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import numpy as np
import torch
import matplotlib.pyplot as plt

from torchvision import datasets
import torchvision.transforms as transforms

batch_size = 64

# transforms
transform = transforms.ToTensor()

# train and validation data
train_data = datasets.MNIST(root='data', train=True,
                                   download=True, transform=transform)

val_data = datasets.MNIST(root='data', train=False,
                                  download=True, transform=transform)

# training and validation data loaders
train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size,
                                            shuffle = True)
val_loader = torch.utils.data.DataLoader(val_data, batch_size = batch_size,
                                            shuffle = False)

import torch.nn as nn
import torch.nn.functional as F

# define a simple linear VAE
class LinearVAE(nn.Module):
    def __init__(self, input_size, hidden_dims):
        super(LinearVAE, self).__init__()
 
        # encoder
        self.enc1 = nn.Linear(input_size, hidden_dims*4)
        self.enc2 = nn.Linear(hidden_dims*4, hidden_dims*2)
 
        # decoder 
        self.dec1 = nn.Linear(hidden_dims, hidden_dims*4)
        self.dec2 = nn.Linear(hidden_dims*4, input_size)

    def reparameterize(self, mu, log_var):
        """
        :param mu: mean from the encoder's latent space
        :param log_var: log variance from the encoder's latent space
        """
        std = torch.exp(0.5 * log_var) # standard deviation
        eps = torch.randn_like(std) # `randn_like` as we need the same size
        sample = mu + (eps * std) # sampling as if coming from the input space
        return sample
 
    def forward(self, x):
        # encoding
        x = F.leaky_relu(self.enc1(x), 0.2)
        x = self.enc2(x).view(-1, 2, hidden_dims)
        # get `mu` and `log_var`
        mu = x[:, 0, :] # the first feature values as mean
        log_var = x[:, 1, :] # the other feature values as variance
        # get the latent vector through reparameterization
        z = self.reparameterize(mu, log_var)
 
        # decoding
        x = F.leaky_relu(self.dec1(z), 0.2)
        reconstruction = torch.sigmoid(self.dec2(x))
        return reconstruction, mu, log_var

input_size = 784
hidden_dims = 64

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
lvae = LinearVAE(input_size, hidden_dims).to(device)
print(lvae)

import torch.optim as optim

lr = 0.0002

lvae_optimizer = optim.Adam(lvae.parameters(), lr=lr)
criterion = nn.BCELoss(reduction='sum')

def final_loss(bce_loss, mu, logvar):
    """
    This function will add the reconstruction loss (BCELoss) and the 
    KL-Divergence.
    KL-Divergence = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)
    :param bce_loss: recontruction loss
    :param mu: the mean from the latent vector
    :param logvar: log variance from the latent vector
    """
    BCE = bce_loss 
    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    return BCE + KLD

def train(lvae, train_loader):
    lvae.train()
    running_loss = 0.0
    for batch_i, (data, _) in enumerate(train_loader):
        data = data.to(device)
        data = data.view(data.size(0), -1)
        lvae_optimizer.zero_grad()
        reconstruction, mu, logvar = lvae(data)
        bce_loss = criterion(reconstruction, data)
        loss = final_loss(bce_loss, mu, logvar)
        running_loss += loss.item()
        loss.backward()
        lvae_optimizer.step()
    train_loss = running_loss/len(train_loader.dataset)
    return train_loss

from torchvision.utils import save_image
import pickle as pkl
samples = []

def validate(lvae, val_loader):
    lvae.eval()
    running_loss = 0.0
    with torch.no_grad():
        for batch_i, (data, _) in enumerate(val_loader):
            data = data.to(device)
            data = data.view(data.size(0), -1)
            reconstruction, mu, logvar = lvae(data)
            bce_loss = criterion(reconstruction, data)
            loss = final_loss(bce_loss, mu, logvar)
            running_loss += loss.item()
        
            # save the last batch input and output of every epoch
            if batch_i == len(val_data)//val_loader.batch_size - 1:
                num_rows = 8
                both = torch.cat((data.view(batch_size, 1, 28, 28)[:16], 
                                  reconstruction.view(batch_size, 1, 28, 28)[:16]))
                samples.append(both)
                # save_image(both.cpu(), f"/content/drive/My Drive/Colab Notebooks/outputs/output{epoch+1}.png", nrow = num_rows)
    val_loss = running_loss/len(val_loader.dataset)
    return val_loss

# from google.colab import drive
# drive.mount('/content/drive/')

train_loss = []
val_loss = []

num_epochs = 100

for epoch in range(num_epochs):
    train_epoch_loss = train(lvae, train_loader)
    val_epoch_loss = validate(lvae, val_loader)
    train_loss.append(train_epoch_loss)
    val_loss.append(val_epoch_loss)
    print('Epoch [{:3d}/{:3d}] | train_loss: {:6.4f} | val_loss: {:6.4f}'.format(
                    epoch+1, num_epochs, train_epoch_loss, val_epoch_loss))
    
with open('train_samples.pkl', 'wb') as f:
    pkl.dump(samples, f)

# Plot Training and Validation Loss of VAE vs. Epochs
fig, ax = plt.subplots()
train_loss = np.array(train_loss)
val_loss = np.array(val_loss)
plt.plot(train_loss.T, label='train_loss')
plt.plot(val_loss.T, label='val_loss')
plt.title("Training and Validation Losses")
plt.legend()

# helper function for viewing a list of passed in sample images
def view_samples(epoch, samples):
    fig, axes = plt.subplots(figsize=(28,5), nrows = 2, ncols = 16, sharey=True, sharex=True)
    for ax, img in zip(axes.flatten(), samples[epoch]):
        img = img.detach()
        ax.xaxis.set_visible(False)
        ax.yaxis.set_visible(False)
        im = ax.imshow(img.reshape((28,28)), cmap='Greys_r')

with open('train_samples.pkl', 'rb') as f:
    samples = pkl.load(f)

view_samples(-1, samples)